{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e572682",
   "metadata": {},
   "source": [
    "# 01_data_preprocessing\n",
    "\n",
    "이 노트북은 원본 CSV(앱 사용/설문/수면)를 uid×week 단위로 병합해 분석 테이블을 생성합니다. 설문 점수(PHQ-9/GAD-7/Stress) 산출, 카테고리 피벗, 수면 지표 집계, 결측 대치, 초→시간 파생 컬럼 생성 후 저장합니다. (데이터 비공개)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21e090c",
   "metadata": {},
   "source": [
    "셀 1 — 설정/임포트/경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "899a5cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /home/biot/github/.venv/lib/python3.12/site-packages (4.0.0)\n",
      "Requirement already satisfied: packaging in /home/biot/github/.venv/lib/python3.12/site-packages (25.0)\n",
      "Requirement already satisfied: setuptools in /home/biot/github/.venv/lib/python3.12/site-packages (80.9.0)\n",
      "Requirement already satisfied: pandas in /home/biot/github/.venv/lib/python3.12/site-packages (2.3.1)\n",
      "Requirement already satisfied: pyarrow in /home/biot/github/.venv/lib/python3.12/site-packages (21.0.0)\n",
      "Requirement already satisfied: py4j==0.10.9.9 in /home/biot/github/.venv/lib/python3.12/site-packages (from pyspark) (0.10.9.9)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/biot/github/.venv/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/biot/github/.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/biot/github/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/biot/github/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/biot/github/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# TL;DR: CSV 로드 → 점수화/피벗/집계/조인/결측대치 → *_hours 생성 → Parquet 저장\n",
    "import sys, os\n",
    "!{sys.executable} -m pip install -U pyspark packaging setuptools pandas pyarrow\n",
    "\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import (\n",
    "    col, avg, split, expr, sum as spark_sum\n",
    ")\n",
    "import ast\n",
    "import pathlib\n",
    "\n",
    "# 입력 경로 (로컬 환경에 맞게 조정)\n",
    "APP_USAGE_CSV    = \"./../all_data/filtering_complete_app_usage.csv\"\n",
    "RESPONSE_CSV     = \"./../all_data/response_week_mapping_adjusted.csv\"\n",
    "SLEEP_CSV        = \"./../all_data/sleep_week_mapped.csv\"\n",
    "SLEEP_DIARY_CSV  = \"./../all_data/sleep_diary_week_mapped.csv\"\n",
    "\n",
    "# 출력 경로1\n",
    "pathlib.Path(\"results/tables\").mkdir(parents=True, exist_ok=True)\n",
    "PARQUET_OUT_DIR = \"results/tables/processed_weekly\"  # ← 확장자 없이 폴더명\n",
    "SAMPLE_OUT  = \"results/tables/processed_weekly_sample.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb97afd2",
   "metadata": {},
   "source": [
    "셀 2 — Spark 세션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "025f3579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새 세션 생성\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AppUsageMentalHealth-Preprocess\") \\\n",
    "    .config(\"spark.sql.session.timeZone\", \"UTC\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c491de",
   "metadata": {},
   "source": [
    "셀 3 — 데이터 로드(+타입)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "941e8fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_usage_df    = (spark.read.option(\"header\", True).csv(APP_USAGE_CSV)\n",
    "                   .withColumn(\"duration\", col(\"duration\").cast(\"double\")))\n",
    "raw_response_df = spark.read.option(\"header\", True).csv(RESPONSE_CSV)\n",
    "sleep_df        = spark.read.option(\"header\", True).csv(SLEEP_CSV)\n",
    "sleep_diary_df  = spark.read.option(\"header\", True).csv(SLEEP_DIARY_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c475f1",
   "metadata": {},
   "source": [
    "셀 4 — 설문 점수 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ad2f18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_score(answer_list, weight_list):\n",
    "    if not isinstance(answer_list, list):\n",
    "        return 0\n",
    "    for i, ans in enumerate(answer_list):\n",
    "        if ans:\n",
    "            return weight_list[i]\n",
    "    return 0\n",
    "\n",
    "def parse_questionnaire(q_list_str, weight_list, filter_options=None):\n",
    "    total = 0\n",
    "    try:\n",
    "        q_list = ast.literal_eval(q_list_str)\n",
    "        for q in q_list:\n",
    "            if filter_options and q.get('options') != filter_options:\n",
    "                continue\n",
    "            total += calc_score(q.get('answers'), weight_list)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66f98ee",
   "metadata": {},
   "source": [
    "셀 5 — 설문 점수 DataFrame 생성 (RDD→DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6770340c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+----+----------+----------+------------+\n",
      "|uid                         |week|PHQ9_score|GAD7_score|Stress_score|\n",
      "+----------------------------+----+----------+----------+------------+\n",
      "|05U1A5bmcnUUycZ6SYAdqhuu3ck2|0   |1         |0         |2           |\n",
      "|05U1A5bmcnUUycZ6SYAdqhuu3ck2|1   |0         |0         |0           |\n",
      "|05U1A5bmcnUUycZ6SYAdqhuu3ck2|2   |1         |0         |2           |\n",
      "|05U1A5bmcnUUycZ6SYAdqhuu3ck2|3   |0         |0         |0           |\n",
      "|05U1A5bmcnUUycZ6SYAdqhuu3ck2|4   |0         |0         |2           |\n",
      "+----------------------------+----+----------+----------+------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "response_rdd = raw_response_df.rdd.map(lambda r: Row(\n",
    "    uid = r['uid'],\n",
    "    week = int(r['week']),\n",
    "    PHQ9_score = parse_questionnaire(r['PHQ-9'], [0,1,2,3]),\n",
    "    GAD7_score = parse_questionnaire(r['GAD-7'], [0,1,2,3]),\n",
    "    Stress_score = parse_questionnaire(\n",
    "        r['Stress Questionnaire'], [0,1,2,3,4],\n",
    "        filter_options=['전혀 그렇지 않다','약간 그렇다','웬만큼그렇다','상당히그렇다','아주 그렇다'])\n",
    "))\n",
    "response_df = spark.createDataFrame(response_rdd).dropDuplicates([\"uid\",\"week\"])\n",
    "response_df.orderBy(\"uid\",\"week\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c39038",
   "metadata": {},
   "source": [
    "셀 6 — 앱 사용 집계 → 카테고리 피벗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4aa2238c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키 중복 방지\n",
    "app_usage_df = app_usage_df.dropDuplicates([\"uid\",\"week\",\"category\"])\n",
    "\n",
    "app_summary_df = (app_usage_df\n",
    "                  .groupBy(\"uid\",\"week\",\"category\")\n",
    "                  .agg(spark_sum(\"duration\").alias(\"duration\")))\n",
    "\n",
    "app_pivot_df = (app_summary_df\n",
    "                .groupBy(\"uid\",\"week\")\n",
    "                .pivot(\"category\")\n",
    "                .sum(\"duration\")\n",
    "                .na.fill(0.0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ce37e2",
   "metadata": {},
   "source": [
    "셀 7 — 수면 집계 (HH:MM:SS → 분 변환 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "959f083c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meanConfidence 평균\n",
    "sleep_agg_df = (sleep_df\n",
    "    .filter(col(\"week\").isNotNull())\n",
    "    .withColumn(\"meanConfidence\", col(\"meanConfidence\").cast(\"double\"))\n",
    "    .groupBy(\"uid\",\"week\")\n",
    "    .agg(avg(\"meanConfidence\").alias(\"mean_confidence_sleep\"))\n",
    ").dropDuplicates([\"uid\",\"week\"])\n",
    "\n",
    "# 수면 다이어리: \"HH:MM:SS\" → 분\n",
    "sleep_diary_min = (sleep_diary_df\n",
    "    .filter(col(\"week\").isNotNull())\n",
    "    .withColumn(\"parts\", split(col(\"midawake_duration\"), \":\"))\n",
    "    .withColumn(\"midawake_duration_min\",\n",
    "                col(\"parts\").getItem(0).cast(\"double\")*60 +\n",
    "                col(\"parts\").getItem(1).cast(\"double\") +\n",
    "                col(\"parts\").getItem(2).cast(\"double\")/60.0)\n",
    ")\n",
    "sleep_diary_agg_df = (sleep_diary_min\n",
    "    .groupBy(\"uid\",\"week\")\n",
    "    .agg(avg(\"midawake_duration_min\").alias(\"midawake_duration_sleep\"))\n",
    ").dropDuplicates([\"uid\",\"week\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8c487f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app_pivot StringType()\n",
      "+----+\n",
      "|week|\n",
      "+----+\n",
      "| 8.0|\n",
      "| 7.0|\n",
      "| 6.0|\n",
      "| 1.0|\n",
      "| 4.0|\n",
      "+----+\n",
      "\n",
      "response IntegerType()\n",
      "+----+\n",
      "|week|\n",
      "+----+\n",
      "|   2|\n",
      "|   0|\n",
      "|   8|\n",
      "|   4|\n",
      "|   6|\n",
      "+----+\n",
      "\n",
      "sleep StringType()\n",
      "+----+\n",
      "|week|\n",
      "+----+\n",
      "| 8.0|\n",
      "| 7.0|\n",
      "| 6.0|\n",
      "| 1.0|\n",
      "| 4.0|\n",
      "+----+\n",
      "\n",
      "sleep_diary StringType()\n",
      "+----+\n",
      "|week|\n",
      "+----+\n",
      "| 5.0|\n",
      "| 2.0|\n",
      "| 1.0|\n",
      "| 7.0|\n",
      "| 8.0|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# week 타입이 데이터프레임마다 다른 경우가 발생하여 spark가 STRING '8.0' → BIGINT 로 casting 실패\n",
    "# -> 모든 df의 week int로 정규화하여 해결\n",
    "for name, df in [(\"app_pivot\", app_pivot_df),\n",
    "                 (\"response\", response_df),\n",
    "                 (\"sleep\", sleep_agg_df),\n",
    "                 (\"sleep_diary\", sleep_diary_agg_df)]:\n",
    "    print(name, df.schema[\"week\"].dataType)\n",
    "    df.select(\"week\").limit(5).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0740831",
   "metadata": {},
   "source": [
    "셀 8 — 조인 & 결측 대치 → *_hours 생성 → 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91030b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, regexp_replace\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "def normalize_week_int(df):\n",
    "    # 1) 문자열/실수 혼재 대비: 문자열로 바꿨다가\n",
    "    df = df.withColumn(\"week_str__\", col(\"week\").cast(\"string\"))\n",
    "    # 2) 흔한 패턴 '.0' 제거 (예: '8.0' -> '8')\n",
    "    df = df.withColumn(\"week_str__\", regexp_replace(col(\"week_str__\"), r\"\\.0$\", \"\"))\n",
    "    # 3) 최종 int 캐스팅 (실패 시 NULL -> 조인에서 자연히 걸러지거나 필요시 fill)\n",
    "    df = df.withColumn(\"week\", col(\"week_str__\").cast(IntegerType())).drop(\"week_str__\")\n",
    "    return df\n",
    "\n",
    "# ⬇⬇⬇ 조인 전에 반드시 실행\n",
    "app_pivot_df     = normalize_week_int(app_pivot_df)\n",
    "response_df      = normalize_week_int(response_df)\n",
    "sleep_agg_df     = normalize_week_int(sleep_agg_df)\n",
    "sleep_diary_agg_df = normalize_week_int(sleep_diary_agg_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9af2c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: /home/biot/github/AppUsageMentalHealthAnalysis/notebooks/results/tables/processed_weekly\n"
     ]
    }
   ],
   "source": [
    "# 조인\n",
    "final_df = (app_pivot_df\n",
    "            .join(response_df, [\"uid\",\"week\"], \"inner\")\n",
    "            .join(sleep_agg_df, [\"uid\",\"week\"], \"left\")\n",
    "            .join(sleep_diary_agg_df, [\"uid\",\"week\"], \"left\"))\n",
    "\n",
    "# 결측 평균 대치\n",
    "mean_conf = final_df.select(avg(\"mean_confidence_sleep\")).first()[0]\n",
    "mean_mid  = final_df.select(avg(\"midawake_duration_sleep\")).first()[0]\n",
    "final_df = final_df.na.fill({\n",
    "    \"mean_confidence_sleep\": float(mean_conf) if mean_conf is not None else 0.0,\n",
    "    \"midawake_duration_sleep\": float(mean_mid) if mean_mid is not None else 0.0\n",
    "})\n",
    "\n",
    "# 1) 점(.) 들어간 컬럼을 전부 언더바(_)로 변경\n",
    "for c in final_df.columns:\n",
    "    if \".\" in c:\n",
    "        final_df = final_df.withColumnRenamed(c, c.replace(\".\", \"_\"))\n",
    "\n",
    "# 2) 초→시간 파생\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "sec_cols = [c for c in final_df.columns if c.startswith(\"AppCategory_\")]\n",
    "for c in sec_cols:\n",
    "    final_df = final_df.withColumn(f\"{c}_hours\", col(c) / 3600.0)\n",
    "\n",
    "# uid, week 중복 제거\n",
    "final_df = final_df.dropDuplicates([\"uid\",\"week\"])\n",
    "\n",
    "# 저장\n",
    "final_df.write.mode(\"overwrite\").parquet(PARQUET_OUT_DIR)\n",
    "final_df.limit(50).toPandas().to_csv(SAMPLE_OUT, index=False)\n",
    "\n",
    "print(\"✅ Saved:\", os.path.abspath(PARQUET_OUT_DIR))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
